type_label: complex_tool_calling
streaming: false
metadata:
  sambanova_environment_name: "Cloud Prod" 
  fastcoe_commit: "N/A"

# Base URLs for each provider
urls:
  sambanova_base_url: "https://api.sambanova.ai/v1"
  groq_base_url: "https://api.groq.com/openai/v1"
  cerebras_base_url: "https://api.cerebras.ai/v1"
  fireworks_base_url: "https://api.fireworks.ai/inference/v1"
  together_base_url: "https://api.together.xyz/v1"

# Provider - model alias mapping models declared here are going to be evaluated
model_mappings:
  SambaNova:
    Meta-Llama-3.1-405B-Instruct: "not_available"
    Meta-Llama-3.3-70B-Instruct: "Meta-Llama-3.3-70B-Instruct"
    Llama-4-Scout-17B-16E-Instruct: "not_available"
    Llama-4-Maverick-17B-128E-Instruct: "Llama-4-Maverick-17B-128E-Instruct"
    DeepSeek-V3-0324: "DeepSeek-V3-0324"
    DeepSeek-R1-0528: "DeepSeek-R1-0528"
    Qwen3-32B: "Qwen3-32B"
  Fireworks:
    Meta-Llama-3.1-405B-Instruct: "accounts/fireworks/models/llama-v3p1-405b-instruct"
    Meta-Llama-3.3-70B-Instruct: "accounts/fireworks/models/llama-v3p3-70b-instruct"
    Llama-4-Scout-17B-16E-Instruct: "accounts/fireworks/models/llama4-scout-instruct-basic"
    Llama-4-Maverick-17B-128E-Instruct: "accounts/fireworks/models/llama4-maverick-instruct-basic"
    DeepSeek-V3-0324: "accounts/fireworks/models/deepseek-v3-0324"
    DeepSeek-R1-0528: "accounts/fireworks/models/deepseek-r1-0528"
    Qwen3-32B: "accounts/fireworks/models/qwen3-30b-a3b"
  Groq:
    Meta-Llama-3.1-405B-Instruct: "not_available"
    Meta-Llama-3.3-70B-Instruct: "llama-3.3-70b-versatile"
    Llama-4-Scout-17B-16E-Instruct: "meta-llama/llama-4-scout-17b-16e-instruct"
    Llama-4-Maverick-17B-128E-Instruct: "meta-llama/llama-4-maverick-17b-128e-instruct"
    DeepSeek-V3-0324: "not_available"
    DeepSeek-R1-0528: "not_available"
    Qwen3-32B: "qwen/qwen3-32b"
  Cerebras:
    Meta-Llama-3.1-405B-Instruct: "not_available"
    Meta-Llama-3.3-70B-Instruct: "llama-3.3-70b"
    Llama-4-Scout-17B-16E-Instruct: "llama-4-scout-17b-16e-instruct"
    Llama-4-Maverick-17B-128E-Instruct: "not_available"
    DeepSeek-V3-0324: "not_available"
    DeepSeek-R1-0528: "not_available"
    Qwen3-32B: "qwen-3-32b"
  Together:
    Meta-Llama-3.1-405B-Instruct: "meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo"
    Meta-Llama-3.3-70B-Instruct: "meta-llama/Llama-3.3-70B-Instruct-Turbo"
    Llama-4-Scout-17B-16E-Instruct: "meta-llama/Llama-4-Scout-17B-16E-Instruct"
    Llama-4-Maverick-17B-128E-Instruct: "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
    DeepSeek-V3-0324: "deepseek-ai/DeepSeek-V3"
    DeepSeek-R1-0528: "deepseek-ai/DeepSeek-R1"
    Qwen3-32B: "Qwen/Qwen3-235B-A22B-fp8-tput"

# OpenAI client options
max_retires: 2
timeout: 30